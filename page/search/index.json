[{"content":"总结下利用 redis 生成流水号的一个解决方案。\n序列号部分 得益于 redis 的原子性与其自增方法 INCR，我们业务方法并不需要线程锁，即可获取一个并发安全的自增序列号；随后将序列号的 key 精确到秒，我们就可以获得一个秒级别的自增序列号。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 val dateStr = now.format(DateTimeFormatter.ofPattern(\u0026#34;yyMMddhhmmss\u0026#34;)) val redisKey = \u0026#34;order_seq:$dateStr\u0026#34; val seq = redis.opsForValue().increment(redisKey) ?: throw IllegalStateException(\u0026#34;Redis INCR 失败\u0026#34;) // MAX_SEQ = (2 shl 14) -1 require(seq \u0026lt;= MAX_SEQ) { \u0026#34;超过每秒最大订单数限制\u0026#34; } if (seq == 1L) { // 设置过期时间，避免 Redis 键爆炸（设置为2秒即可） redis.expire(redisKey, Duration.ofSeconds(2)) } 时间戳部分 再将序列号拼接上时间戳就是一个相对完整的流水号了；时间戳很好获取，根据当前服务器系统时间计算即可。\n这里我们的时间戳格式为 yyMMddhhmmss。这样的话 250413120000 就代表 25 年 4 月 13 号 12 点 0 分 0 秒，再拼接上序列号 0001 ，流水号就是 25_04_13_12_00_00_0001。\n1 2 3 val dateInt = dateStr.toInt() // 假定序列号只有 14 位 val currentNumber = (dateInt.toLong() shl 14) or seq 时钟回拨问题 如此简单就基本完成了核心逻辑，但很不「高可用」。如果业务服务器（即调用 redis INCR 的服务器）的系统时间回拨了呢？那么新序列号可能会比老序列号更小，例如系统时间回拨一年，重启服务，则会生成 24 年的流水号 24_04_13...。\n可见让这个流水号生成器「高可用」的主要的挑战在于预防「时钟回拨」。\n当服务器的系统时间异常了，原因可能会五花八门，不过导致的根本问题都是「新序列号比老序列号更小」。\n至于 redis 重启问题，在我们这个生成逻辑下，redis 得是秒级重启。如果 redis 花费了一秒多的时间重启成功，那么序列号可以透明的、自动的从零重新开始自增，基本不用考虑这个问题。\n我们需要将「新序列号」与「（上一个）旧序列号」比较，才能知道新序列号是否正确。\n1 private val prev = -1L 1 2 3 4 if (currentNumber \u0026lt; prev) { // TODO: 解决时钟回拨问题 throw IllegalStateException(\u0026#34;时钟回拨：$currentNumber \u0026lt; $prev\u0026#34;) } 现在的问题变成了 prev 怎么读写。\n即时更新序列号 很方便的是，我们（业务服务器）是生成者，生成新序列号后更新下变量即可。\n1 2 3 4 if (currentNumber \u0026lt; prev) { throw IllegalStateException(\u0026#34;时钟回拨：$currentNumber \u0026lt; $prev\u0026#34;) } prev = currentNumber 出现了，竟态条件！前面说到我们的生成器只依赖 redis 的 INCR，本来是不需要线程锁的，但现在 prev 变量的出现，导致生成器线程不安全了。\n可以直接给生成器方法上锁，但不够轻便和优雅。因为我们的序列号是秒级别内并发才需要同步，不需要时时刻刻同步，可以乐观一点，使用 AtomicLong。\n1 private val lastNumber = AtomicLong(0) 简单的实现，利用原子变量尝试单次更新。\n1 2 3 4 5 6 7 val updated = lastNumber.updateAndGet { prev -\u0026gt; if (currentNumber \u0026gt; prev) currentNumber else prev } if (currentNumber \u0026lt; updated) { throw IllegalStateException(\u0026#34;时钟回拨，无法生成订单号\u0026#34;) } 当我们需要在时钟回拨时做些处理的时候，我们就可以基于原子变量封装一个乐观锁。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 // 保证线程安全地维护 lastNumber，避免时钟回拨 while (true) { val prev = lastNumber.get() if (currentNumber \u0026lt; prev) { // throw IllegalStateException(\u0026#34;时钟回拨，无法生成订单号\u0026#34;) // 或者等待时间修复，重新生成 currentNumber currentNumber = waitClockSyncAndGenerate() continue } if (lastNumber.compareAndSet(prev, currentNumber)) { break } } 启动时恢复序列号 及时更新很完美，但当业务服务器重启，就会丢失 lastNumber 值，需要一个行为在服务启动时恢复 lastNumber。\nplan 1 - Redis 缓存 首当其冲，我们的 redis 服务器还健在，直接从 redis 服务器中恢复。\n1 2 3 4 5 6 7 fun postInit() { val last = redis.opsForValue().get(LAST_NUMBER_KEY) if (last != null) { lastNumber.set(last) return } } plan 2 - 生命周期 Hook 如果 redis 服务也重启了，还是要想办法持久化 lastNumber。什么时候持久化比较好呢，因为持久化是一个 IO 操作，在每次生成时即时持久化不够优雅，最好是通过各种手段监控到业务服务的销毁后，在业务服务启动前持久化 lastNumber。\n当然设计允许的话，也可以直接从相关业务表里恢复，例如 select max(orderNumber) from order，获取最大（新）的订单号。\n1 2 3 4 5 val last = sql.query(\u0026#34;select max(orderNumber) from order\u0026#34;) if (last != null) { lastNumber.set(last) return } 如果这个生成器专门为这个业务服务，这样做没什么不好。若是一个通用生成器，就不够优雅了，会使我们的生成器要和某个业务强绑定。\n紧随其后的就是业务服务器本地文件，当业务服务是正常停止的，一般都会给我们提供一些 hook，例如 spring 的 @PreDestory 注解。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 @PreDestory fun preDestory() { try { LAST_NUMBER_FILE.parentFile.mkdirs() LAST_NUMBER_FILE.writeText(lastNumber.get().toString()) } catch (e: Exception) { println(\u0026#34;写入本地 lastNumber 失败：${e.message}\u0026#34;) } } @PostConstructor fun postInit() { // Plan 2: 尝试从本地文件恢复 if (LAST_NUMBER_FILE.exists()) { val fileVal = LAST_NUMBER_FILE.readText().trim().toLongOrNull() if (fileVal != null) { lastNumber.set(fileVal) } } } plan 3 - 守卫服务 但前面的还是不靠谱，单机服务、机房淹水，来不及正常停止服务，这些容错方案就不起作用了。\n我们可以抽象一个 StateStorage 出来，交给下游实现，主要作用是持久化 lastNumber，例如 ``\n1 2 3 4 5 6 @PostConstruct fun initLastNumber() { // Plan 3: 尝试从状态存储器恢复 ，大概会是这样 val last = stateStorage.getLast() lastNumber.set(fileVal) } StateStorage 怎么实现就敬请想象了，可以利用心跳检测，服务监控等各种中间件，部署一个外部监控服务（守卫），在一系列连环措施下，终于可以安全的 hook 掉业务服务宕机了。\n或者简单点，让业务服务自己监控自己，实现一个内部的 scheduler ，例如以 heartbeat 的形式持久化 lastNumber。\n其它 关于启动时恢复，是为了解决新序列号过小牵扯出来的问题。那只要我们的业务服务的系统时间恢复正常，解决掉「新序列号 \u0026lt; 旧序列号」的问题。新旧序列号大小比较通过，此时启动时恢复的靠不靠谱就不重要了。\n或者不够优雅也无所谓了，我这个业务很重要，不太关心性能，那就每次生成后即时持久化。\n当然也可以不强依赖 redis，将 redis 抽象成一个原子性质的自增方法，称之为「分发器」。把 redis 作为一种分发器的实现，这样或许会更「通用」一点。\n分布式场景的话，再加上一个 machineid 节点标识位，但也会有\n参考 SnowflakeId | CosId\n","date":"2025-04-13T00:00:00Z","permalink":"https://blog.zonowry.com/posts/generate-time-related-serial-number-in-concurrently/","title":"并发安全的生成一个时间相关的订单流水号"},{"content":" !TIPS 文中提到的软件配置、dotfiles 相关都可以在 zonowry/dotfiles 仓库中找到。\n首先展示成果\n进入 Arch LiveCD 开始安装 硬盘分区 先使用 fdisk 对磁盘分区，至少需要创建一个 fat 格式分区，存放 efi 引导文件。和一个 btrfs 主分区，存放系统文件。\n下文使用 /dev/nvme0n1 作为例子。\n1 2 3 4 5 fdisk /dev/nvme0n1 # 选择一块硬盘进行分区 \u0026gt; g # gpt 分区表，uefi 启动 \u0026gt; n # 新建分区 \u0026gt; ... \u0026gt; w # 保存退出 格式化磁盘 1 2 3 # 主分区 mkfs.vfat /dev/nvme0n1p1 mkfs.btrfs -L arch-btrfs /dev/nvme0n1p2 # 建立 btrfs 分区并命名 Label 挂载分区 \u0026amp; 初始化 btrfs 1 2 mkdir -p /mnt/efi mount /dev/sda1 /mnt/efi 挂载主分区安装系统到磁盘。\nbtrfs 压缩算法区别 Compression\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 mount -t btrfs -o compress=zstd /dev/nvme0n1p2 /mnt btrfs subvol create /mnt/@ btrfs subvol create /mnt/@home btrfs subvol create /mnt/@var-cache btrfs subvol create /mnt/@var-temp btrfs subvol create /mnt/@opt btrfs subvol create /mnt/@swap umount /mnt mount -t btrfs -o compress=zstd,subvol=@ /dev/nvme0n1p2 /mnt mount --mkdir -t btrfs -o subvol=@home /dev/nvme0n1p2 /mnt/home mount --mkdir -t btrfs -o subvol=@opt /dev/nvme0n1p2 /mnt/opt mount --mkdir -t btrfs -o subvol=@var-cache /dev/nvme0n1p2 /mnt/var/cache mount --mkdir -t btrfs -o subvol=@var-temp /dev/nvme0n1p2 /mnt/var/temp btrfs fi mkswapfile /mnt/swap/swapfile --uuid clear --size 16G swapon /swap/swapfile 替换 pacman 安装源 加速 pacman 安装速度。用 reflector 自动配置 pacman 使用国内镜像源。\n1 reflector --age 24 --country China --sort rate --verbose --protocol http --protocol https --save /etc/pacman.d/mirrorlist 也可以编辑 mirrorlist 文件，解开 [China] 下的镜像源注释并注释掉官方源，或者用手机上网搜索最新的国内 archlinuxcn 镜像源吧，然后手动敲上。\npacman 配置 如果安装时遇到签名错误，应该可以通过以下方式解决。如果你的 live 不是很新那么大概率会签名错误，所以推荐先执行以下，也没坏处。\n1 2 3 4 pacman-key --init pacman-key --populate archlinux # Syy 刷新下 pacman -Syy archlinux-keyring 开始安装： 下载安装系统内核，以及网络管理、ssh 之类的必备软件。\nPS：如果是当作日常桌面系统使用，系统内核推荐安装 linux-zen ，看 linux-lqx(zen) 官网介绍 是比较适合桌面/游戏用户的。但会遇到因为不是官方标准内核，所以会碰见部分驱动需要用 dkms 自己编译的情况。例如 nvidia ，简单起见就先用 linux 标准内核吧，以后可以再安装切换到 linux-zen，也不麻烦。\nPPS：如果你是 intel 就安装 intel-ucode，amd 就安装 amd-ucode（大概是这个名字，参考 archlinux wiki 吧）。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 pacstrap /mnt \\ linux \\ linux-firmware \\ base \\ sudo \\ neovim \\ networkmanager \\ openssh \\ git \\ git-lfs zsh \\ grub \\ efibootmgr \\ intel-ucode \\ base-devel \\ devtools \\ btrfs-progs chroot 进入系统 安装完成后，进入系统，方便后续做一些处理。\n1 2 arch-chroot /mnt ln -s /usr/bin/nvim /usr/bin/vim grub 启动项配置 1 2 3 4 5 6 7 8 9 10 11 12 13 mkdir /efi # 挂载第一步创建的 vfat 分区 mount /dev/sda1 /efi # grub uefi 启动项 grub-install --target=x86_64-efi --efi-directory=/efi --bootloader-id=GRUB # TODO vim /etc/default/grub # loglevel=5, nowatchdog # grub 引导/菜单配置 grub-mkconfig -o /boot/grub/grub.cfg 添加用户 设置用户密码，配置普通用户 sudo 权限。\n用户名「zonowry」改成自己的即可。\n1 2 3 4 5 6 7 useradd -m zonowry # 为新用户设置密码 passwd zonowry # 为 root 设置密码 passwd root # 允许新用户使用 sudo 命令， 这里我设置了 sudo 免密码，可以去掉 echo \u0026#34;zonowry ALL=(ALL) NOPASSWD:NOPASSWD:ALL\u0026#34; \u0026gt;\u0026gt; /etc/sudoers fstab 配置 设置系统启动时自动挂载的分区，退出 arch-chroot ，通过 arch 安装脚本自动生成 fstab 配置。\n1 2 exit # 退出 chroot /mnt 环境 genfstab /mnt \u0026gt; /mnt/etc/fstab 建议验证下，生成的是否正确\n1 cat /mnt/etc/fstab ![[cat-fstab.png]]\n重启进入系统 上边的步骤做完，重启应该就可以引导并进入系统了。\n初始化网络 1 2 3 4 5 systemctl enable NetworkManager systemctl start NetworkManager systemctl enable sshd systemctl start sshd 时区本地化配置 1 2 3 timedatectl set-ntp true # ntp 同步时间 timedatectl set-timezone Asia/Shanghai timedatectl # 查看验证 语言本地化配置 可能影响一些系统的提示语言，货币和时间的显示格式。\n程序员的话建议就用 en_US.utf8 吧，一些命令报错，英文的话比较好搜索解决方法。\n1 2 3 4 5 6 7 vim /etc/locale.gen # 解除 en_US.UTF-8 的注释， # :wq 保存退出 # 生成 locale-gen localectl set-locale LANG=en_US.UTF-8 Aur 客户端 一般使用 yay ，不过我图新鲜用的 paru 。其实也不知道具体啥区别，到底哪个好用。感觉除了开发语言不同，功能上都差不多吧。\n去 paru 的 github release 页面下载二进制包，然后解压创建 /usr/bin/paru 软链接就好了。\n1 2 3 4 5 6 7 8 9 10 11 # 或者直接 `wget` ，需要自己判断版本链接。 wget https://github.com/Morganamilo/paru/releases/download/v1.11.2/paru-v1.11.2-x86_64.tar.zst # tar 解压 paru-v1.11.2-x86_64.tar.zst tar xvf paru-v1.11.2-x86_64.tar.zst mkdir /opt/paru mv ./paru /opt/paru chmod +x paru ln -s /opt/paru/paru /usr/bin/paru paru -Syyu hyprland 安装 hyprland，一款平铺桌面管理器。动画流畅，丰富的自定义选项。最好配合 hyprland 官网食用。\n1 pacman -Sy hyprland 安装后可以命令行执行 Hyprland 启动小窥一眼，默认配置比较简陋，win+M 退出继续折腾。\nhyprland 的配置例如动画样式、窗口规则、按键绑定、屏幕设置等不是很重要，默认配置也够用了，且个人差异太大，找个自己喜欢的 dotfiles 参考即可。比较重要的配置是环境变量\nbyprland 环境变量 亲身感受下来是很多疑难杂症都可能和某个环境变量有关，只能靠多搜索多踩坑。\n每个人环境不一样，所以也仅供参考。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 # Some default env vars. env = XDG_CURRENT_DESKTOP,Hyprland env = XCURSOR_SIZE,24 env = QT_QPA_PLATFORMTHEME,qt6ct # change to qt6ct if you have that # env = LIBVA_DRIVER_NAME,nvidia env = XDG_SESSION_TYPE,wayland # env = GBM_BACKEND,nvidia-drm env = GDK_BACKEND,wayland # env = __GLX_VENDOR_LIBRARY_NAME,nvidia env = WLR_NO_HARDWARE_CURSORS,1 env = OZONE_PLATFORM,wayland # env = GLFW_IM_MODULE,ibus env = QT_IM_MODULE,fcitx env = XMODIFIERS,@im=fcitx env = LANG,zh_CN.UTF-8 env = LANGUAGE,zh_CN:en_US env = JDK_JAVA_OPTIONS,-Dawt.useSystemAAFontSettings=on -Dswing.aatext=true -Dswing.defaultlaf=com.sun.java.swing.plaf.gtk.GTKLookAndFeel env = _JAVA_AWT_WM_NONREPARENTING,1 env = AWT_TOOLKIT,MToolkit env = JAVA_HOME,/opt/apps/jdk/jdk1.8.0_261 桌面配置 \u0026amp; 常用应用 以下软件大多都和 dotfiles 配置相关，可以在 dotfiles 找到各个软件对应的配置。例如 ~/.config/fontconfig/fonts.conf 字体配置。\nMust Have 中文字体是必备的，但也看个人喜好。不过字体对 waybar 等应用影响比较大，很容易出现在编辑器里很好看，但在 GUI 界面上很难看（对不齐之类的）。需要自己调整或者采用别人的挑选好的字体。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 # 权限 pacman -Sy polkit-kde-agent \\ dunst \\ pipewire \\ wireplumber \\ xdg-desktop-portal-hyprland \\ xdg-desktop-portal-wlr \\ xdg-desktop-portal-gtk \\ qt5-wayland \\ qt6-wayland # 字体 ttf-lxgw-wenkai \\ ttf-iosevka-nerd \\ wqy-microhei paru -S ttf-cascadia-code-nerd \\ ttf-lxgw-wenkai-screen \\ noto-fonts-emoji \\ ttf-firecode-nerd \\ ttf-material-design-icons-extended fc-cache -vf # 刷新字体缓存 输入法 得益于 Hyprland 作者好像也是日语输入法用户，所以 Hyprland 的 input-method 相关协议较其它 wayland 合成器更为完善。现在 Hyprland 安装 chrome，fcitx5 之后，基本是开箱即用了，~~（只需要设置 fcitix5 环境变量与 electron flags）~~好起来了！\n1 2 3 4 pacman -S fcitx5-im \\ fcitx5-rime \\ fcitx5-configtool \\ fcitx5-material-color 强推下雾凇拼音 https://github.com/iDvel/rime-ice\n1 paru -S rime-ice-git 常用软件 下列应用不一定适合所有人，大多都有平替，仅供参考。\n1 2 3 4 5 pacman -Sy kitty \\ wofi \\ waybar \\ thunar \\ nfs-utils 1 2 paru -Sy visual-studio-code-bin \\ google-chrome 美化 前置软件 1 2 3 4 paru -Sy kvantum \\ qt5ct \\ qt6ct \\ nwg-look 以下是我采用的主题图标，若不喜欢。也可以去 pling.com 找自己喜欢的，安装方式大同小异。\n主题 1 2 3 git clone --depth=1 https://github.com/vinceliuice/Orchis-kde.git cd ./Orchis-kde ./install.sh 图标 1 2 3 git clone --depth=1 https://github.com/vinceliuice/Tela-icon-theme.git cd ./Tela-icon-theme ./install.sh -a 指针 phinger-cursors\n1 2 paru -S phinger-cursors # 打开 nwg-look 设置指针即可 安装好主题图标后，依次使用 kvantum、nwg-look、qt5ct、qt6ct 软件应用下主题图标即可，qt5ct/qt6ct 的主题选择 kvantum。最后重启 Hyprland 让主题生效。\n命令行美化 1 pacman -S fzf oh-my-zsh 1 git clone --depth=1 https://github.com/romkatv/powerlevel10k.git ${ZSH_CUSTOM:-$HOME/.oh-my-zsh/custom}/themes/powerlevel10k zsh 插件，有些是自带的，第三方插件都有 git 仓库。 以下都可以通过例如 git clone https://github.com/zsh-users/zsh-autosuggestions ${ZSH_CUSTOM:-~/.oh-my-zsh/custom}/plugins/zsh-autosuggestion 来安装。\n1 2 3 4 5 6 7 8 sudo git zsh-autosuggestions zsh-syntax-highlighting fzf-zsh-plugin docker docker-compose zsh-shift-select 备份 一系列繁琐操作后，得到了一个纯净的系统，当务之急是备份当前环境，避免重装。得益于 btrfs，备份十分简单。\ntimeshift 只会备份名为 @、@home 的子卷，够用了。\n1 sudo pacman -S timeshift grub-btrfs timeshift 需要 root， wofi 调起 timeshift，polkit 输入密码后，没有反应。懒得排查原因了，只能 sudo -E timeshift-gtk 启动了，问题不大。\n1 sudo -E timeshift-gtk 按照操作来即可创建一个快照了。\n小技巧 wev 命令行工具，查看键码 hyprctl clients 查看当前客户端列表信息，可以用来排查是否是 xwayland 启动。 ","date":"2024-09-20T00:00:00Z","image":"https://blog.zonowry.com/posts/install-hyprland-on-arch-and-simple-beautify/image-2024_02_25_03_47_36_hu_3f2972b32582c175.png","permalink":"https://blog.zonowry.com/posts/install-hyprland-on-arch-and-simple-beautify/","title":"Arch + Hyprland 安装美化手册"},{"content":"前言 有时候会觉得 BT 以及可以实现 P2P 的 VPN 很”魔法“，因为一直对端到端直连的技术细节好像知道，又好像不知道。借着捣鼓了一阵 wireguard 组网，写下本文加深下对 P2P 理解。\n配置这些工具没什么难度，但背后的技术路径却很有意思。 tailscale 那片著名的 NAT 文章讲的很全面，本文也是主要结合这篇文章总结下 NAT 穿透的各种难度。\n完整又原始的 wireguard 单纯用 wireguard 实现中转组网的话很简单，只需要一个中转服务器。且有很多的开源工具辅助，例如 wireguard-ui、easy-wireguard\u0026hellip;利用这些工具可以管理各个 peer，生成 conf 文件。\nwireguard 已经足够“完整“了。跨平台的客户端、声明式的配置、自动化的路由 AllowIPs 等等。如上段所说，wireguard 算的上最轻便的组网方案了，一般情况下很好用。\n但想用 vanilla wireugard 实现 peer-to-peer 直连的话，就要手动配置每个 peer 的 endpoint。如果 peer 的数量是 n ，那么这将是一个 O(n^2 - n) 的工作，还不包括路由转发的配置工作，并且每个 peer 的公网地址也很难是固定的。\n这些任务很繁重，没有在 github 上找到一个 vanilla wireguard 的自动化处理这些任务的工具，不过基于 wireguard 的上层工具倒是不少。\n最终采用了 headscale，是 tailscale 服务器的开源版，基于 wireguard 实现。也算是一个 wireguard 自动化配置工具。简单配置下即可实现端到端直连需求，tailscale 客户端会自动添加 iptables 规则等路由操作。\n回到正题，接下来从简单到困难，盘点下 NAT 穿透的各种难度。\n最简陋的环境 首先抽象一个“很简陋”的 NAT 环境下的端到端直连，简陋是指对端防火墙允许一切传入。此时只要一端想办法得到对端的公网地址后，就可以直连。如何得到对端的公网地址也很简单，架设一个类似 DDNS 服务的“协调器”，两个端点访问协调器时，协调器自然可以看到端点的公网地址。\n这个协调器服务称之为 STUN (Session Traversal Utilities for NAT)，STUN 记录了每个端点的公网 IP，可以告诉各个端点对端的地址，让其自己去建立连接。\n只要各个端点向 STUN 上报自己的地址就可以，虽然很简单，但这样确实就足够了。\n最常见的环境 STUN 的原理看上去十分简单，其实就是很简单。不过当 NAT 环境变得不“简陋”，即对端不允许一切传入，只允许传出的响应数据包。这也是大多 NAT 防火墙的默认配置。此时 STUN 会受到一些限制。\n想象一下这种情况下 STUN 协助端到端建连的过程：首先一端建立一个 socket 访问 STUN 获取对端的地址，接着再建立一个 socket 访问对端，这时当然会被对端的 NAT 防火墙拦截，因为对端拒绝一切传入。\n穿透只能到此为止了吗？前面说到，有状态防火墙允许一种“特殊的传入”，即自身传出的响应，否则我们就没办法愉快问对方是 GG 还是 MM 了。\n回到 STUN 的限制上，就是我们要让对端防火墙认为我们的是“响应”。记得吗，对端也向 STUN 传出了数据包，所以 STUN 知道对端 NAT 此时开放（映射）的地址（端口），这个端口可以接受响应传入。\n另一端则可以向对端的这个端口发送数据包，随后基于这个端口开始通信~~，可以开始为所欲为了~~。显而易见我们用来直连（穿透）的 socket 重用了访问 STUN 的 socket。\n这就是为什么与 STUN 通信和 NAT 穿透要使用同一个 socket。\n有点难度的环境 STUN 的限制似乎也不是很麻烦，最终来看只是限制只使用一个端口而已。\n不过都知道 NAT 按照所谓的“锥形“分为四个等级，这个“锥形”划分比较抽象，我们不用。更容易理解的分类是 easy nat 和 hard nat，根据“是否依赖目的地址”划分的。\neasy nat 是不依赖目的地址的一种 nat，顾名思义是较为容易穿透 (?) 的 NAT。Esay NAT 的特点是：内网机器同一个 socket 发出去数据包，经过 nat 映射后，nat 为此 socket 创建的端口是固定的。不管这个 socket 是发往 1.1.1.1，还是发往 2.2.2.2 的，即目的地址不相关。这也是我们上一步“最常见的环境”中可以成功直连的原因。\nHard NAT 就是依赖目的地址那种了，特点是：内网机器就算用同一个 socket 发出的数据包，经过 NAT 后，如果发往目的地址不一致。NAT 会为该 socket 的每一个目的地址映射一个不同的端口，等待目的地址的响应。\n回到 STUN 上，当 Hard NAT 的一端向 STUN 服务器上报地址时，STUN 拿到的是独属于自己（STUN）的地址，只有 STUN 的响应被允许传入，对端的“响应”会被 Hard NAT 拦截。\n想象一个理想的流程，肯定得由 Hard NAT 的一端先向 Easy NAT 的对端发送请求，Esay NAT 的一端拿到了独属于自己的地址（端口），开始基于这个端口开始通信。好像很自然，但问题是此时 Easy NAT 会拦截掉这个数据包，Hard NAT 给我们开放的这个专属端口遗落进网络长河中。\n简单的魔改下 NAT 设备，让其记录下这个对端地址，如果可以办得到的话。除此以外，我们如何找到这个被遗落的端口？\n前文说到 Hard NAT 设备对于 socket 的目的地址是关心的。即同一个 socket 发往 1.1.1.1 与发往 2.2.2.2 的数据包在经过 Hard NAT 设备映射后，是两个端口。所以当两端向对端发送数据包时，各个端点 NAT 设备映射的端口只有自己那端的 NAT 设备自己知道。\n众所周知端口的数量只有 65535 个，让 Easy NAT 背后的端点暴力猜测那个“专属”端口也不是不可以~~（傲娇早就退环境了啊！）~~。不过从 1 开始遍历有点傻，让 Hard NAT 背后的端点多开点 socket 向 Easy NAT 发几次包，再利用点算法（生日悖论）提高猜中的概率。\n当 Easy NAT 一端猜中端口，就可以基于这个端口通信了。\n搞不定的环境 当一端是 Easy NAT，另一端是 Hard NAT 的话，限制又多了一个穿透必须由 Hard NAT 端发起。但只要从 STUN 服务器拿到对端 IP，再花费几秒钟猜测一次端口，这也是可以接受的。\n可当两端都是 Hard NAT 呢？记得吗，Hard NAT 的映射规则是：\n\\[socket,dest ip:port\\]，一端打开的每个端口（socket）猜测对端端口时，会映射一个新的端口，对端也是同理，一端的每个端口都要猜 65535 次，单纯暴力的话大概需要两端各进行 65535^2 次，如此巨大的复杂度就算上生日悖论算法也是难以接受。\n所以在两端都是 Hard Nat 情况下的继续采用 STUN 协助打洞目前来看有点不太现实，只能走中转方案。\n99.99% 可以成功的环境 最常见的一种 NAT 实现就是 Linux 内核 netfilter 框架了，用 iptables 等工具可以简单的配置转换规则，连接的应答包也会自动应用“反向规则”。例如我们只需要配置 SNAT，当应答数据包经过 netfilter hook 时，会自动应用 DNAT （反向 SNAT）。\n这都依托于有状态防火墙的链路追踪，基于这个特性，我们可以得出结论：不管两端的链路经历了多少 NAT 设备节点，最关键的 NAT 节点，始终只有距离发出端和接收端最近的那两个 NAT 节点。就像引用透明的函数式，不管函数多么复杂，其没有副作用。（正如本文的引言，数据包出走半生，归来时一定得是 NAT 设备期望的返回，令人忍俊不禁）\n综上所述，只要确认有一端是 Easy NAT 就 99.99% 可以让 N2N 转为 P2P。当出现一端是 Easy NAT 却没有打洞成功的话。肯定是经过了奇奇怪怪的“NAT”，例如各种 proxy vpn。与 STUN 通信经过了 proxy，发出端变成了 proxy 节点，距离发出端最近的 NAT 也就变成了 proxy 节点的 NAT。对于这个 NAT ，我们能做的只有什么都不做。\n百分百可以成功的环境 端口转发，或者公网 ip，选一个吧。\n参考 \\[译\\] NAT - 网络地址转换（2016） \\[译\\] 深入理解 iptables 和 netfilter 架构 ","date":"2024-08-16T00:00:00Z","permalink":"https://blog.zonowry.com/posts/nat-in-different-environments/","title":"NAT 穿透在不同环境下的差异"},{"content":"说实话研究数据库的底层对常见的项目帮助不大，或者说不受重视，更多是在业务编排上。数据库随便建建，增删改查随便写写，功能就完成了，项目就上线了。但程序员总要有些追求，并且数据库的细节知识很泛用。如 Schema、索引、数据结构、事务、锁，这些知识不止是数据库独有的，说是学习数据库，不如说是借由数据库来学习一下这些知识。不参透数据库设计，就像四大名著不读红楼梦，后面忘了…。\n本文主要讨论关系型数据库，可能会顺带一提与 NoSql 相关的知识。\n数据库的 Schema 数据库大多是通过索引、表、数据类型等特性管理数据。但对于关系型数据库来说，需要从强类型说起。强类型主要是降低调用方的负担，编译期间就会给出报错，将类型错误扼杀在生产之前，不过需要编写强类型的一方“负重前行”。不过大家都会在类型上偷点懒， typescript 经常会被戏称为 anyscript 似乎是个很好的例子。\n所谓“负重”，其实就是我们使用 Schema （模式） 描述一个元素。Graphql 的接口定义是一个例子，关系型数据库更是如此。使用 Schema 描述表、列、索引、视图、以及外键约束各种关系等。不用钻研 Schema 是如何运作的，只需知道只有数据不会平白无故形成，为此你必须要提供一个 Schema 。\n数据库是通过 Schema 实现对数据结构的高度控制（强类型）。进行诸如 create table 操作时，本质就是在写一个 Schema 。\nNoSQL 一般会被称为 Schemaless 数据库，侧面说明了 NoSQL 弱模式的特性。不过数据通常会有相当“连贯”的结构，为了建立索引，我们还是会显式的编写部分 Schema 描述这些 连贯（consistent structure） 的数据。\n索引的数据结构 索引字面上很容易理解，例如 HashMap 和 Array，它们的 键值 (HashCode) 和 元素下标 (Index) 就是其索引。但数据库作为一个系统，在索引上的设计上就略微繁琐一些了，不过索引目的都是为了提高搜索效率，避免检索时枚举所有数据。\n索引本质是一种数据结构，将数据按照某种规律排列就形成了索引，借用别人的话来说“索引就是排序的艺术”。\n考虑在 1 亿条数据中，找到 id 为 4396 的数据这个场景。暴力遍历最差需要枚举 1 亿次才能找到。那 B+Tree 结构如何优化索引，考虑到有序树基本都是参考了二分法的思想，所以先从简单的二分法开始。\n1 亿条数据一直对半分，最坏大概只需要 $log_2(1,0000,0000) \\approx 26$ 次查询，可以看出仅仅一个平衡的二叉树（二分法）就可以指数级提升查找效率。\n而数据库通常采用平衡多叉树结构，也就是 B+ Tree，B+ Tree 与二叉树最大的区别就是其多叉，即底数 N 可能大于 2，也就降低了阶数。但是每阶可能需要比较 N 次，这样算下来效率好像没有比二叉树好。不过结合现实世界考虑，通过索引磁盘 IO 读取数据的次数约等于树的阶数，多叉树远比二叉树的阶数少，减少了磁盘 IO 次数。\n简单的理解一次 IO 然后 CPU 内存批量判断索引，比精确但频繁的 IO 读取索引挨个判断更快，CPU 是比磁盘快 IO 得多的。这也就是数据库系统中 B+ Tree 也就比二叉树的查询速度更快的原因了。\n但显而易见的一棵多叉树，工作机制类似二分法，搜索效率很高~~（那么代价是什么）~~。但当我们增删数据时，需要分裂、合并叶子节点，那这棵树的结构会受到很大波动。因为树需要按照 B+ Tree 的规则（定义）平衡自己，称之为页的分裂与合并，一般是为了保持每个页的大小为 16K。所以常说建立索引后查询变快，但会导致增删改变慢。\n表的存储结构 模式 (Schema) 与 索引 (Index) 终归和“物理数据”不太相关，物理数据是如何存储的？主要与表的存储结构相关。存储结构直接影响到数据的存储方式，间接影响到增删改查。关系型数据库的存储结构有两种：索引组织表 (Index Organzation Table) 与 堆表 （Heap Table）。\nNoSql 因为不使用关系表，在 NoSql 中或许可以类比的概念是数据模型。例如键值对模型、文档模型、图模型等。NoSql 按照模型定义把数据存储成非结构化（unstructured）数据。\n索引组织表 表的存储结构依附于索引，物理数据存储在一个索引的 B+ Tree 上，也可以说索引直接指向物理数据，找到了索引，就找到了数据，这个索引称之为聚集索引。物理数据只有一份，所以每个表也只能有一个聚集索引，一般为主键（唯一索引）。除聚集索引外的索引就是二级索引，也被称为辅助索引。\n可以想象聚集索引是有序的，所以物理数据也是有序的，这意味着物理数据存储位置是随索引动态变化的，二级索引只能指向一个聚集索引（主键 ID）。当使用二级索引检索数据时，获取到聚集索引（主键 ID），再用主键 ID 去检索物理数据，这个过程叫作回表。\n堆表 堆表则没有聚集索引，顾名思义堆表是一个 Heap，物理数据无序的堆在一起。数据与索引分开存储，通过索引只能获取到数据的物理地址（页号、偏移位置），再根据地址去直取物理数据。\n表面上看这与索引组织表的二级索引机制大致相同，可以说堆表的索引全部都是二级索引，但堆表的二级索引不存在回表问题。与索引表的二级索引相比，存储的是数据的物理地址，所以少了回表步骤，不过与聚集索引相比，还是慢一点的。\n另外显而易见由于堆表无序，所以存储速度比索引表快一些。\n对于索引的优化 聚集索引 聚集索引影响一个表的物理数据存储顺序，数据存储到哪个位置取决于这个聚集索引，会影响存储速度。不过找到索引，也就找到了数据，提升查询速度。数据和索引聚集到一起了，两者间有很强的关系。然后我们把这个索引叫做 聚集索引，这种表结构的存储方式叫做 索引组织表。因为聚集索引影响表的物理数据存储顺序，所以一个表只能有一个聚集索引，通常是根据主键建立的 B+ Tree 索引。\n根据聚集索引特性，我们可以优化的点：\n范围查询时尽量命中聚集索引，可以降低回表次数。 更新数据时尽量不更改聚集索引本身。 尽量不要离散的增删数据。例如隔 10 条数据删一条这种。 MySQL 的 InnoDB 存储引擎就采用索引组织表。\n二级索引 (辅助索引/非聚集索引) 二级索引的通常只存储了一个指向数据行存储位置的指针~~，当然还有索引列本身（作为键）~~。当我们通过二级索引列查询数据时，会先从辅助索引中找到记录的位置，这个位置上存放了数据行的指针。\n在索引组织表结构下拿到的这个数据指针是主键（聚集索引）的值。 通过主键的值再去聚集索引树里查询数据，这个过程叫做回表，SQL 语句耗时长的多数原因。 在堆表结构下拿到的数据指针则是数据存放的绝对位置（页码、偏移量）。 在堆表结构下，所有索引都可以看作是二级索引。 简单想象一个场景，现在我们想根据员工年龄查询数据，但我们目前只有一个用户 ID 列的聚集（主键）索引，数据库需要枚举所有数据再进行筛选。这时候我们就可以为年龄列建立一个二级索引。有了年龄列索引，数据库会先通过年龄列索引查询到符合条件的数据指针，再通过数据指针取到数据。\n堆表与索引表的二级索引在读取数据时小有差异，不过宏观上看都是进行了两次 IO 读写，一次读取索引结构，一次读取数据页。这里可以把索引表的“数据页”看成聚集索引树，所以需要用主键指针重新走一遍聚集索引，查找数据。虽然都是两次 IO，不过这个过程肯定是不如堆表的绝对位置指针快的，不过也有优化方法。\n覆盖索引 覆盖索引特性可以改善索引组织表的回表现象。简单来说，只要我们保证要查询的数据列都是索引列，这样找到二级索引就找到了所需要的数据，避免了再去聚集索引中查询数据。\n例如我们要只想查询用户的 age 和 name，而恰好我们建立了 name 列和 age 列二级组合索引。\n1 create index on user(age, name) 那我们此时应该避免写出类似 select * 语句。\n1 2 3 -- 可能查询到不需要的列，会触发回表 select * from user where age \u0026gt; 20 order by name 原因是查询 user 表没有索引的列会导致回表。例如 create_time 没有索引，数据库会再去聚集索引中取 create_time 数据，可我们的业务又不需要 create_time，白白浪费性能。\n1 2 select name, age, create_time from user where age \u0026gt; 20 order by name 只需要通过二级索引覆盖了要查询的所有数据，因为 (age,name) 组合索引本身就是 age, name 列的数据，通过这个索引筛选数据时，找到了索引，就找到了数据，所以避免了回表操作。\n1 2 3 select name, age from user where age \u0026gt; 20 order by name; -- or select age from user where age \u0026gt; 20; 数据库锁 并发领域中常见术语：锁。\n或许可以先看看我的《[[怎样安全的并发编程]]》文章 😳。\n数据库根据颗粒度划分出行级锁、页级锁、表级锁。这些锁顾名思义就很容易理解了。根据行为来说的话又有共享锁和互斥锁。共享锁能够将数据设为只读，任一线程都可以读（共享数据），不过任一线程企图更新数据时都会被阻塞，直到共享锁释放。互斥锁则是为了保障写入数据的一致性，表现形式就是其它线程无法再对次数据添加任何锁。只有持有互斥锁的线程对该数据可读可写。\n结合一个并发的先读后写的场景的业务场景。比如支付订单减少库存。A 用户和 b 用户同时了购买同一个商品，且同时支付成功。我们的业务逻辑是，首先为了保险，需要判断库存是否还有剩余，如果有剩余，就减少商品库存。\n1 2 -- upodate 语句会自动请求互斥锁（锁定需要的数据） update product set stock = stock - 1 where product_id = x and stock \u0026gt; 0; 这句 sql 利用了互斥锁，保证了数据的一致性。但如果放在日经问题“抢购/秒杀”上来看，同时上万个用户进行秒杀，数据一致性是没问题。但由于竞争互斥锁会出现阻塞，那响应速度可想而知，且数据库链接是昂贵的资源，开了连接却阻塞等待，~~（占着茅坑不拉屎），~~小鸡承受不住呀。\n缓存一招鲜秒了，将 stock 这个数据缓存。当然，缓存那边怎么去实现，就牵扯到更多的缓存数据库设计了，一般是缓存好（预热/懒加载）数据，在缓存中原子性的更改缓存数据（库存）。然后在某个时间点进行一次简单地数据库更新写入，保证缓存与数据库的一致性。\n1 2 -- 在某个时刻，写入最新缓存数据。节流数据库写入请求 update product set stock = #{stock_from_cache} where product_id = x 也没什么好说的，只要对并发编程理解足够深，把类似概念套用到数据库的锁、事务上也是一样的~~，只要打好基础，写啥都轻松~~。\n参考 What is a Schemaless Database? MySQL 为什么不用数组、哈希表、二叉树等数据结构作为索引呢 PostgreSQL 与 MySQL 比较 数据库之堆表和索引组织表 - 墨天轮 ","date":"2024-04-18T00:00:00Z","permalink":"https://blog.zonowry.com/posts/how-to-retrieve-data-in-relational-database/","title":"关系型数据库如何检索数据"},{"content":"折腾历程 目的本来是实操 k8s 的，部署时搞了一堆花里胡哨的，虽然因为复杂度与资源消耗原因放弃了这套方案~~（=白折腾）~~，但对理解 k8s 的组成部分帮助很大。\n曾经的解决方案：\n部署工具：kubeadm 容器运行时 CRI： cri-o 容器底层交互接口 OCI ：crun 容器网络 CNI： cilium 不过部署完这套，小鸡性能吃紧，遂换到了 k3s。\n但将 k3s 作为 HomeServer 使用一段时间后，手写各种 depolyment yaml 很是折磨，远不比 docker-compose 方便，维护工作反而变麻烦了，一度想放弃折腾。\n不过心底还是想坚持用 k8s (大概是跟风吧），痛点不过是手写 yaml，命令行看日志等等琐碎操作，这些问题 rancher 都可以解决。不过写一些 k8s 的 yaml 后再用 webui 会很容易上手。\n也有其它的 management，不过 rancher 比较流行，虽然很重。轻量一点的也有一个 GitHub - skooner-k8s.，没啥资源的家庭服务器感觉可以考虑。\nLXC 前置条件 1. LXC 的权限 设置容器 /proc /sys 读写权限、cgroup 权限等\n1 2 3 4 vim /etc/pve/lxc/{lxc id}.conf # 放开权限 unprivileged: 0 1 2 3 4 lxc.apparmor.profile: unconfined lxc.cgroup.devices.allow: a lxc.cap.drop: lxc.mount.auto: \u0026#34;proc:rw sys:rw\u0026#34; 2. 为容器创建 /dev/kmsg 容器一般不存在 /dev/kmsg 内核日志，k3s 大概会向此“文件”输出消息，所以需要保证容器启动后存在这个文件，容器里存在一个 /dev/console，可以用这个“文件”作替身用。\n自动创建 /dev/kmsg 1 vim /usr/local/bin/conf-kmsg.sh 1 2 3 4 5 #!/bin/sh -e if [ ! -e /dev/kmsg ]; then ln -s /dev/console /dev/kmsg fi mount --make-rshared / 创建 systemd 开机执行脚本 1 vim /etc/systemd/system/conf-kmsg.service 1 2 3 4 5 6 7 8 9 [Unit] Description=Make sure /dev/kmsg exists [Service] Type=simple RemainAfterExit=yes ExecStart=/usr/local/bin/conf-kmsg.sh TimeoutStartSec=0 [Install] WantedBy=default.target 启用生效 1 2 3 chmod +x /usr/local/bin/conf-kmsg.sh systemctl daemon-reload systemctl enable --now conf-kmsg 安装 k3s 从官方中国源安装，默认装最新版 注意版本号，要与 rancher 兼容 1 curl -sfL https://rancher-mirror.rancher.cn/k3s/k3s-install.sh | INSTALL_K3S_MIRROR=cn INSTALL_K3S_VERSION=v1.28.7+k3s1 sh -s - server 需要安装 rancher 支持的 k3s/k8s 版本。k3s 版本列表：K3s； rancher 兼容表： Rancher Manager v2.8.3 | SUSE\n安装 Rancher 1. 安装 Helm 1 2 3 curl -fsSL -o get_helm.sh https://raw.githubusercontent.com/helm/helm/main/scripts/get-helm-3 chmod 700 get_helm.sh ./get_helm.sh 为了使用 Helm，需要 Kubeconfig 环境变量\n1 2 3 4 5 6 7 cat \u0026gt;\u0026gt; /etc/profile \u0026lt;\u0026lt; EOF export KUBECONFIG=/etc/rancher/k3s/k3s.yaml EOF source /etc/profile # 验证一下 helm list -A 2. Helm 添加仓库 1 helm repo add rancher-stable https://releases.rancher.com/server-charts/stable 国内可以用镜像： https://rancher-mirror.rancher.cn/server-charts/stable ，版本可能落后。\n3. 为 Rancher 创建命名空间 你需要定义一个 Kubernetes 命名空间，用于安装由 Chart 创建的资源。这个命名空间的名称为 cattle-system：\n1 kubectl create namespace cattle-system 4. rancher 默认需要 SSL 相关配置 需要安装 cert-manager\n1 kubectl apply -f https://github.com/cert-manager/cert-manager/releases/download/v1.13.1/cert-manager.crds.yaml 5. 部署 rancher 部署后需要通过 hostname 访问 rancher，如果没有 DNS 服务器，应该可以通过修改 hosts 文件映射 ip 访问。\n1 helm install rancher rancher-stable/rancher --namespace cattle-system --set hostname=rancher.my.org --set bootstrapPassword=admin --version 2.8.3 最后部署一个 NEO4J 熟悉一下 rancher（可选） 新建个持久化卷资源 PersistentVolumes HostPath 类型 再新建个持久化卷请求声明 PersistentVolumeClaims 选择刚才建立的 PV 新增 Deployments 为 Pod 指定 PVC 容器镜像：neo4j:5.19.0 配置下 Service 简单点就先 NodePort 了，后面在配 Ingress 加个环境变量 NEO4J_AUTH=user/pwd 可以查看日志、服务状态，启动成功后。 访问 Neo4j http://ip:30075 (nodeport 监听的端口) ","date":"2024-04-15T00:00:00Z","image":"https://blog.zonowry.com/posts/deploy_k3s/image-2024_04_16_12_36_53_hu_c423f12552c35780.png","permalink":"https://blog.zonowry.com/posts/deploy_k3s/","title":"在 PVE 容器上部署 k3s + rancher"},{"content":"启用路由器的 telnet 为了启用 telnet，需要手动升级路由器固件到开发版，开发版固件可以在 GitHub - YangWang92/AX6S-unlock 仓库下载。(miwifi_rb03_firmware_stable_1.2.7.bin)\n通过 SN 码获取路由器 root 密码 在网页 Xiaomi Router Developer Guide \u0026amp; Tools 内输入路由器 SN 码，计算出 root 密码。\nTelnet 登录路由器开启 ssh 等服务 登录 telnet，用户名 root，密码你刚刚拿到了。\n1 telnet 192.168.31.1 执行以下三条命令，开启些服务，主要是 ssh，照做就是了。\n1 2 3 4 5 nvram set ssh_en=1 \u0026amp;\u0026amp; nvram set uart_en=1 \u0026amp;\u0026amp; nvram set boot_wait=on \u0026amp;\u0026amp; nvram set bootdelay=3 \u0026amp;\u0026amp; nvram set flag_try_sys1_failed=0 \u0026amp;\u0026amp; nvram set flag_try_sys2_failed=1 nvram set flag_boot_rootfs=0 \u0026amp;\u0026amp; nvram set \u0026#34;boot_fw1=run boot_rd_img;bootm\u0026#34; nvram set flag_boot_success=1 \u0026amp;\u0026amp; nvram commit \u0026amp;\u0026amp; /etc/init.d/dropbear enable \u0026amp;\u0026amp; /etc/init.d/dropbear start 下载纯净（原版）的 ImmortalWrt 固件 ImmortalWrt Firmware Selector\n搜索自己的路由器型号，下载 factory.bin。如果没有话只能自己编译了\n通过 scp 上传固件 scp 上传刚刚下载的原版固件。\n1 scp path/to/file/factory.bin root@192.168.31.1:/tmp 然后 ssh 登录路由器，刷写 openwrt 固件。\n1 2 # 刷入上一步 scp 传过来的底包 mtd -r write /tmp/factory.bin firmware 访问 openwrt 配置 lan 接口 原版的 openwrt 网址是 192.168.1.1。这个 IP 地址可能会和光猫冲突，所以首先编辑 网络/接口/lan，修改网段为你喜欢的，例如 10.0.0.1。\n配置路由器拨号 配置好 lan 接口后，再配置下 wan 口的 PPPoE 信息，确保路由器可以联网~\n安装 argon 管理界面主题 仓库地址： GitHub - jerrykuku/luci-theme-argon。\n安装的版本：2.3.1\n1 2 3 4 5 opkg install luci-compat opkg install luci-lib-ipkg # scp path\\to\\file\\luci-theme-argon_2.3.1_all.ipk root@10.0.0.1:/tmp # 安装 scp 传递下载好的 ipk opkg install /tmp/luci-theme-argon*.ipk 安装 openclash 仓库地址： GitHub - OpenClash。\n安装的版本：v0.46.003-beta\n1 2 # 同理先使用 scp 上传到路由器，然后 opkg 安装 opkg install /tmp/luci-app-openclash_0.46.003-beta_all.ipk 安装后重启路由器，就可以看到“服务”菜单了。按照自己需求配置 openclash ，接入互联网。\n为什么不装整合包 整合包挺方便的，不过内核都比较老旧，直接更新还容易变砖。而且大多服务/插件都没什么用。\n这样是获得了一个最新版本的 openwrt 内核，不会再碰见内核版本不兼容问题了，可以放心的安装各种新版插件了。\n最主要的是它很干净哇！\n参考 \\[2-2\\]AX6S 闭源无线驱动 Openwrt 刷机教程/固件下载-小米无线路由器及小米网络设备-恩山无线论坛 360T7 安装 immortalwrt 官方原版固件（含 Luci Web 页面），供新手参考-360 无线路由器及其他 360 网络设备-恩山无线论坛 ","date":"2024-03-31T00:00:00Z","image":"https://blog.zonowry.com/posts/steps-to-flash-redmi-ax6s-router-with-openwrt/image-2024_04_01_20_17_39_hu_8864f3df43231599.png","permalink":"https://blog.zonowry.com/posts/steps-to-flash-redmi-ax6s-router-with-openwrt/","title":"红米 AX6S 路由器刷入纯净最新 ImmortalWrt 步骤"},{"content":"引言 说到并发，首先会想到多线程。若只关注多线程如何使用，却对并发编程没有深入的了解，很容易在代码里挖坑，变成这个段子的模样：“从前有个程序员遇到了一个性能问题。他想，没事，我懂，用线程就好了。现他有在个两题了问“。\n为了避免这种情况，我们该思考“为什么需要多线程，为什么 js 里没有多线程？”等诸类问题。将多线程看成是并发的一种手段，也就是让我们往下面 （the lower）走一点，越过线程理解并发编程。\n如果逻辑控制流在时间上重叠，那么它们就是并发的（concurrent） —— 《CSAPP》\n理论指导实践 分析 thread（线程）、coroutine（协程）、reactive（反应式）、event/task queue（任务队列） 等各种并发手段。不讨论它们的用法、优劣，而是关注它们的的相似之处——它们实际都是通过编排、调度逻辑控制流实现的并发。所以只需要搞清楚它们是如何调度执行单元的，就掌握了核心科技。\n逻辑控制流，底层一点的理解是硬件电路形成的一组逻辑。应用级一点的解释是一个可以被执行的内容，可能是线程、协程、一个可观察对象 Observable、Subscription、FutureTask、Event Callback\u0026hellip;\u0026hellip; 等等。不过用 CSAPP 书中的逻辑控制流表示一个可执行内容有点极简，所以下文就称之为任务或执行单元吧，代表一个可被执行的片段（you know it）。\n抢占式调度 首先是最常见的抢占式调度，执行单元间呈竞争关系，A 任务与 B 任务互相争夺执行机会。最常见的例子是“操作系统内核利用 CPU 时钟中断，达成多线程并发“。每次中断都代表某个线程抢到了 CPU 时间片”。因为 CPU 中断是纳秒级的，实际效果是内核在飞快的切换执行单元以交错执行。提供一种所有执行单元在并行的假象。在多核心 CPU 下，内核的抢占式调度也足以实现真正的并行。\n抢占式调度下，执行单元无法确定自己什么时候会被执行，且任何时刻都可能会被中断执行。反过来说，只要我们基于此特性，处理好执行单元的竞争与中断，就可以实现一个抢占式调度器。也可以看出抢占式调度的好处是不会存在独占情况——某个执行单元永远占用着 CPU。因为每个执行单元都有被执行的机会，就像在等红绿灯一样。\n协作式调度 协作式调度可以引出一大堆技术，例如 IO 多路复用 、迭代器、事件驱动 等等。\n它们都有一个点——主动让渡控制权，或者说主动挂起的（释放并等待）。A 任务与 B 任务可以在合适的时机主动让渡出控制权。特点是持有控制权的任务主动中断，~~抛开现实不谈（例如 CPU 中断），~~这也突出了协作式调度的优点与理念——“调度不会影响顺序性“。因为我们是主动让出的，继续执行时可以找到让渡时的节点来保证顺序性，也可以理解为调度器会帮我们将执行单元恢复到让渡前一刻的状态，然后就像没让渡过一样继续执行。\n协作式调度，执行单元知道自己什么时候会让出，但同时对程序员也是无感知的，因为当再次拿到控制权时，协作式调度器可以保持顺序性1。这个特性提高了程序员们的并发编程体验。于是出现了很多协作式调度框架。抽象的角度看，不论是 Reactive Stream，还是 coroutine ，在我看来都是协作式调度的不同实现。它们都有着执行单元可以主动挂起的特性，与其它执行单元协作式的完成逻辑。\n实践中的问题 是时候为线程正名一下了，虽然前面段落回避提及线程，但现在开始线程必不可少，因为线程作为系统内核最小的调度单位，实现并行基本2离不开线程。协程、反应式等用户态的并发模型到底还是跑在线程上的。\n单线程的话，就不存在着并发编程中的问题，无非就是线程安全了。原因只有并发环境下访问共享可变的状态一种。但为什么共享状态这个操作会引起问题？因为数据读写不一致。为什么会读写不一致？需要搞清楚并发下计算机是如何读写状态的。\n专业一点的说共享状态就是竞态条件。也说明两个执行单元可能有某种依赖关系，它们需要协商好谁可以使用这个状态。\n缓存一致性 假设计算机的内存非常快且非常大，那我们就不需要担心缓存一致性问题了，为什么？因为每次读取状态，都是最新的状态，这是纳秒级实时读写。（最后说一次，时间要加速了），这是美好的未来。可现实世界的计算机是有极限的（我不做电子计算机了！JOJO！），计算机的妥协设计是每个 CPU 核心都有一块独立的非常快，但非常小的内存，称之为高速缓存；再加一块速度尚可（远不及 CPU 计算速度），但非常大的内存，它就是我们的内存条，称之为主内存。\n两块内存特性互补，让数据读写不至于拖慢 CPU 计算。妥协的代价就是数据一致性问题，或者说数据可见性问题。因为 cpu 运行一个线程时，需要先从主内存读取数据拷贝到高速缓存里，之后就是 cpu 与高速缓存的时间了，期间 CPU 会适时的将高速缓存里的堆积数据刷写到主内存中。问题出在线程间可以共享数据，会牵扯到数据同步（最小的分布式了吧？），有数据同步就不可避免的有一致性问题了，与分布式、数据库领域的数据一致性大同小异。\n高级语言为了避免我们太操心这些事情，抽象了运行时内存区域（堆栈、常量区、方法区\u0026hellip;），然后设计了内存模型，负责线程间通信，保证线程间数据同步，线程空间隔离。让多线程容易使用，程序员们要操心的事情变少了（不用和系统底层打交道），但也也让线程间通信变的陷阱重重。\n读写有序性 不考虑性能，假设不存在中间缓存，每个 CPU 核心实时读写主内存，可以保证所有线程共享数据的一致性。但这样能解决线程安全问题吗？还是不行，因为计算机并不会 line by line 的执行代码，因为计算机/虚拟机会在不影响语义的情况下，优化代码的执行顺序。也就是优化后应该与不优化执行的结果一致，称之为重排序。\n想象多个线程只共享一个变量时，我们的假设确实有用——指令重排序对我们来说不会是问题。但多个线程共享多个变量时，指令重排序的情况就很复杂了。线程是独立的，无法确保另一个线程的重排序会不会影响。举个简单的例子，方便理解：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 var value: Int = 0; var flag: Boolean = false; ​ fun init() { value = 8; flag = true; } ​ fun getValue() { if (flag) { println(value); } } fun main() { // thread 1 可能会先执行 flag = true，后执行 value = 8 thread { init(); } // 在这钟情况下，thread 2 则有可能 print 0; thread { getValue() } } 如果没有重排序，因为我们知道线程就算是抢占的，交错执行。但也不会造成 print 0 的情况，因为赋值 value = 8 是原子操作（下面介绍）。2 个线程，2 个共享变量，非常简单代码，使我的大脑宕机，爱来自\u0026hellip;..\n真实的代码会更复杂，可见编译器和 CPU 很难确保重排序优化在多线程多共享的情况下不会出现异外结果。就像这个理论不该出现的 print 0，即使我们理解线程的交错执行，且阅读并人脑编译了代码可能的执行过程，但因为指令重排序的存在，这一切变得混沌。\n原子一致性 进一步假设~~（现在是幻想时间）~~，不存在指令重排序，不存在缓存一致性问题，相当于 java 的 volatile 关键字的效果。线程安全问题还会存在吗？还是会存在，因为程序不仅有指令、数据，还有算法（逻辑）。\n编排一系列指令形成逻辑，可以称之为算法或操作（算法帅一点，所以下文统称算法）。既然是一系列指令，那么每条指令都有可能会被系统内核中断或被其它并行的线程影响，导致算法结果不符合预期。而原子性的百科定义是：\n原文：线性一致性（Linearizability），或称原子一致性或严格一致性指的是程序在执行的历史中在存在可线性化点 P 的执行模型，这意味着一个操作将在程序的调用和返回之间的某个点 P 起作用。这里“起作用”的意思是被系统中并发运行的所有其他线程所感知。\n大概意思是如果某个指令被执行，其它线程一定会知道这个指令被某个线程执行了，就像单线程一样，等待执行的代码行可以感知到已执行的代码行。或者常见的理解基于「原子是不可再分割的最小物质」并发原子性就是「不可再打断的最小操作序列」。这个解释与数据库的原子性「要么全都成功，要么全都失败」异曲同工，当然细说还是有区别的，例如并发的原子性不会 rollback 。\n我的解释是，如果一个算法执行过程中，即使被内核中断切换了线程，或存在共享状态的并行线程，也不会被影响结果。就可以说这个算法是线程安全的，也可以理解为算法不会被打断，具有原子性。\n原子性我认为是比较容易理解的，因为非原子性算法造成的影响用户态可以很明显的感知到。例如两个线程同时执行 i++ ，最后 i 的结果通常会小于预期值。\n无论如何，这是最后一步了，不会继续假设了。只要保证原子性，就可以使线程同步，线程同步了，线程安全问题自然烟消云散。\n高速的安全并发 步入正题，前文可得，只要我们灵活运用三大特性即可避免线程安全问题。不过我们并发初衷可不是为了安全，而是 fot the speed！速度！\n《Java 并发编程实践》中写过，如何修复线程安全问题：\n如果当多个线程访问同一个可变的状态变量时没有使用合适的同步，那么程序就会出现错误。有三种方式可以修复该问题：\n不在线程之间共享该状态变量 将该状态变量修改为不可变的变量 再访问该状态变量时使用同步 串行编程 先看最简单的一种：在访问该状态变量时使用同步，也就是串行化线程了。\n前文也提到「只要保证了原子性，就可以使线程同步」。可以总结出两种为线程添加原子性的主要方式：\n原子指令：CPU 指令级别的原子操作。如大名鼎鼎的 CAS - 比较并较换 指令。 信号量：是一种底层思想，以信号量的不变性实现出原子指令、线程锁。 原子指令 原子指令比较容易理解，就像定理一样。从 CPU 硬件级别限制了此指令不会被中断，一但执行，不可取消。\n常见的 CAS 原子指令就是实现各种乐观锁的关键，因为 CAS 指令不可被中断，才能保证乐观锁自旋的检测与更新是线程安全的。例如 AtomicInteger。\n原子指令在性能损耗上大大小于整块代码加锁，但使用场景上也比较受限。~~因为不如加锁一把梭简单。~~对于一段多线程代码，需要人脑编译来判断“仅依靠原子指令是否可以保证线程安全“，说多线程优化通常就是在说这个，依靠原子指令让你的线程锁（阻塞）变少。就像乐观锁做的一样，通过 CAS 指令，来应对多读少写的场景。或者直接改变你的算法逻辑\n信号量 以提供互斥为目的的二元信号量常常也称为互斥锁（mutex）。 ——《CSAPP》\n同步线程都知道用线程锁，常用的线程锁基于信号量的思想。使用二元信号量变量实现互斥锁的例子：\n执行线程前，首先获取信号量 如果信号量为 0 ，则挂起线程，等待重启，重启后继续判断信号量。 如果信号量为 1 ，则立即返回，并 - 1，这将导致其它线程挂起，本线程执行。 执行线程后（包括被中断），必须释放信号量： 将信号量 + 1，并尝试重启一个因为此信号量挂起的线程。 然后我的建议是不要在信号量、互斥量、自旋锁、乐观锁、悲观锁、互斥锁等等这些术语上浪费太多脑筋。信号量是底层的一种思想，各种锁都是基于这个思想实现的，只是互斥的级别不同，根据锁的用途对锁进行了概念上的分类。不用在名字上过于讲究。\n不可变变量 将该状态变量修改为不可变的变量，很容易理解的一种方式。说起来也很简单：你的共享变量不可变了，相当于只允许读取，必然就不涉及同步问题了。\n做起来的话会很艰难，每个线程的数据都像快照一样。数据一致性的控制权回到了你的手里。需要你来编排数据的“流向”，进入什么数据，出来的会是什么，线程没有了副作用，线程的输出你可以预测，就像一条功能明确的加工流水线。\n副作用就是指不会对外界产生影响\n不可变变量，函数式的思想，一种优雅至极的方案，但会让你束手束脚，不过如果完美贯彻函数式，应该会很流畅，不过需要很高的脑力吧\u0026hellip; 不过尽量让变量不可变，从而让函数保持无副作用，是一种好习惯。\n分布式事务 再来看好像最简单的一种：不在线程之间共享该状态变量。作者本意应该不是让我们放弃。\n其实联想一下，不共享状态，每个线程对于变量的当前正确值是没有感知的，把每个线程看作一个分布式节点，像不像分布式里的数据一致性问题？那瞬间就变的很复杂了。\n不共享状态，但我们又需要访问该状态。只要我们可以接受短暂的线程不安全，退一步，就会有很多方案。可以参考分布式事务的一些成熟做法，例如最终一致性、两阶段提交等。~~不过这已经算脱离了线程安全话题了，算是数据设计了。~~简单的介绍一下吧，其实纯编程实现没太大意义，通常结合数据库、消息队列等中间件来实现。\n最终一致性：两个线程执行时，拿到的是共享变量的副本，各自执行完成后，可能还有定时器在不停的纠正数据。 两阶段提交：每个线程执行完毕后，发出准备提交的通知。主线程收到所有线程都准备就绪后，允许各个线程进行提交。然后各个线程开始提交。 多版本并发控制： 本质上我们就是需要一些保险手段，在尽可能不影响线程效率的情况下，保障数据不出错。\n参考 并发之痛 Thread，Goroutine，Actor 既然 CPU 有缓存一致性协议（MESI），为什么 JMM 还需要 volatile 关键字？ 可能会对 rx 的顺序性提出质疑，这里非指过程式一样的代码的编写顺序，例如容易理解的协程的顺序性，而是“可以较为容易”的预测代码执行的顺序。例如 rx 的 obserable.flatmap().reduce().publishOn().map().tap() 例子，还是可以预测出这段代码的整体顺序性的，只是操作符联合起来会很复杂，让人难以理解，不过还是可以说 rx 是有一定顺序性的，毕竟本质上是一个流处理，流的流转过程就是顺序。\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n如果不把异步 IO 看作一个特殊的“线程”，那将 IO 读写操作交由内核调度，注册回调后继续干活，变相实现了一个线程逻辑计算的同时，其它 IO 硬件也正在读写数据（如网卡），实现并行处理：一个 IO 硬件，一个 CPU。虽然多数场景我们都是要挂起线程，等待 IO 硬件响应的。再展开就是 IO 模型的话题了，本文不过多讨论，不过也可以看出 IO 模型与并发编程的关系密不可分。\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","date":"2024-02-29T00:00:00Z","permalink":"https://blog.zonowry.com/posts/safe-concurrent-programming/","title":"怎样安全的并发编程"},{"content":"免责声明 程序员对抽象、设计可能会有不同的习惯。同样一个功能有人用发布订阅，有人用消息队列，他们都有自己的一套设计理念。最终是谁能说服谁的问题，哪一种方式都不是绝对正确的，就像本文一样。\n内容有点偏意识流，不过总结的都是些很简单的东西。文中提到的诸多“本质”，应该会再写一篇来举例说明吧。\n人类智商受限 人类的智商难以理解庞大而复杂的软件系统，所以我们尝试用抽象来设计软件，设法以人类的智商也可以理解庞大的软件系统。\n抽象是什么 管理自己的磁盘时，都会建立类似 Work、Software、Temp、Repo \u0026hellip;之类的文件夹。怎么分类文件夹最合理在这里不重要，重要的是分类文件夹前，肯定会进行的简单的设计。这个设计的思考过程我认为就是正在抽象。\n举个不是很恰当的例子。我们不会为某一个 IDE 单独建立文件夹，来存放用它开发的代码文件。例如 Intellij Projects、Visual Studio Projects 。而是会尝试建立 Projects、Repo、Workspace 存放代码文件。这期间我们就是在抽象，把文件和具体的软件分离开，思考了这些文件的本质是”代码文件“，而非”某款软件的文件“。\n抽象本质就是简化信息，是为了降低复杂度、是控制软件系统混乱程度的外在做功。\n从三层架构开始思考 三层架构是一个很简单的，但抽象程度很高的模式。它可以解释大多数程序的组成：”有对外交互、有核心逻辑、有数据读写“。这就是它的高度抽象，把信息简化到了极致，所有程序都可以遵循三层架构模式写出来。三层本质是规范了代码边界，划分出三层边界：\n用户交互层：接收“用户”的输入，向“用户”输出处理结果。 核心逻辑层：只负责程序的核心“算法”，如何处理数据。 数据交互层：妥协层，内存实现不了持久化，抽象出一个数据读写层代替内存。 代码设计的前期阶段，如何思考出一个模块的组成部分？三层架构给了我们一个优秀的示范。不需要思考功能的太多细节，全力以赴的简化功能的细节，简单直接的阐述功能的本质。\n不过三层架构太抽象了，就像将「用户注册」抽象成「新增数据」，相当于没有细节。如果只从三层中学到了“把代码按照交互、核心、读写划分”的话，那实现细节还是会剪不断理还乱。只会套用三层架构范式，而不去思考功能本质的软件最终会难以维护，也许是屎山多是三层架构的原因（风评被害）。\n最小人力成本 简单的东西却蕴藏大设计，架构大道反而在最简单的三层之中。只要适当的简化信息，边界划分的足够合适，架构最终会形成一个个聚合，开始有了领域驱动的味道。可难点就是边界如何划分的足够合适，信息如何简化才算符合抽象。\n因为现实世界复杂的，软件系统的复杂度是不断熵增的。不变的设计总会有一天会遇到冲击。总会遇见两难抉择：重构还是硬怼？\n例如我曾碰见的 getRowDef(rowIndex) ，起初这个方法是为了获取数据的类型定义，以此解析并转换数据内容。但后来 Excel 变的很复杂，我们需要根据内容来推断列定义。所以方法变成了 getRowDef(rowIndex, rowReader, totalLines, prevRowDef...)，多了很多参数，以便在方法内部推断此行的类型定义。变成了让人困惑的屎山代码：获取数据的类型定义，需要先读取数据，然后再拿定义去转换数据。理念上有了冲突，让人产生了困惑。但还是选择了硬怼，因为这样改动最省力，写好注释后也能让人理解。\n看似上面例子重构一下成本也不大，但其实功能本质已经变了。也就是设计理念变了。类型定义和数据内容的关系变了。重构就要从类型定义和数据内容这种基层代码改起。结合实际工期限制，适当的抽象减轻维护难度就可以了。如果碰到设计瑕疵就要重构，反而会给自己增加压力，延后工期，浪费人力~~，失去工作~~。\n《架构整洁之道》里提到：==“软件架构的终极⽬标是，⽤最⼩的⼈⼒成本来满⾜构建和维护该系统的需求”==。遇到设计瑕疵时，有重构的想法时，需要慎重思考自己新的设计，减少的维护复杂度和花费的精力相比是否值得。\n代码设计 百科对抽象的解释是「找出事物的本质，剥离其它表象、杂质，最终形成一个概念」。\n抽象的本质 务实的看，抽象可以帮助我们简化代码，封装复用、继承多态、接口声明。都是在抽象代码，以形成“某某功能”的概念，实现细节则是在具象（补完）这个概念。这个概念就是前文一直在提到的功能本质、设计理念等抽象的词汇。\n使用第三方库时，遇到一些不清楚的方法，一般只需要在源码中找几个接口定义（注释）看看，或者阅读官网文档的 Api Reference 就能理解。这些框架都是作者的匠心之作，单从它们的版本发布就能略知一二，它们的更新维护通常都是非 breaks 的。屎山才会经常不停的重构，导致 breaks。\n这些框架怎么做到的？虽然框架支持的特性多样且复杂。但框架作者依靠抽象简化了信息，思考本质。不论是修复 bug，还是新增功能，作者只需要确保框架的概念还是不变的。这里的概念相当于其抽象的出发点，或者本质。每次维护、更新只需要确定这个本质不会发生改变。\n信息隐藏 理解抽象，彻底的理解什么是“简化信息”很关键。并非是单纯的精简代码，而是一种形意拳。精简代码只是其形。意在降低复杂度。\n我在《代码大全》里看到信息隐藏时，意识到到这个东西可以和简化信息联系起来，更直观的解释抽象。我们降低复杂度、抽象代码、简化信息。最终达成的效果就是隐藏了代码所蕴含的信息。\n结合一段代码，有点极端但简单地例子。直观的看一下信息隐藏是什么。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 // domain class User { fun login(): Boolean { // 核心逻辑：只有周一允许登录 return if(today() == \u0026#39;周一\u0026#39;) true else false } } // service fun loginService() { val user = getUser() if(!user.login()) { // 错误的 return \u0026#34;登录失败，失败原因：只有周一才能登录\u0026#34; // 正确的 return \u0026#34;登录失败\u0026#34; // “我”不知道失败原因，因为原因被“隐藏”了 } else { // ... } } 例子中，代码的边界体现在「今天是周一才能登录系统」这个核心逻辑。服务层不应该知道这个信息。只应根据业务对象的返回值来做判断，或者说我们隐藏了这个信息。\n为什么”告知用户“「只有周一才能登录」的写法是错误的？因为核心逻辑层只返回了 false，没有说原因。服务层及更上层理应不知道原因，即使所有代码都是同一个程序员写的。\n程序员应该克制，或者说欺骗自己。这样才能保持住代码的边界，即使告知用户「只有周一才能登录」是更好的用户体验，仅从代码设计来看，隐藏信息是首要的。\n简单来说就是，“我”忘记了核心逻辑，业务对象只返回了一个 Boolean，只包含了“登录是否成功”这条信息。这样“我”的做法是「登录失败，但我不知道原因」就很合理了。\n当然上边的例子有点极端。来点实际的例子，就像我们写 java，不用去理解 public void main() 背后发生了什么，只需要知道这是程序的主入口。这就是设计 java 语言的人，隐藏了信息，我们只需要往 main 方法里浇灌屎山代码就行了，降低不少复杂度。\n简化信息，降低复杂度的本质，似乎就是信息隐藏。\n依赖接口 再来理解依赖接口而非实现就很简单了，接口就是隐藏信息的集大成者，如果没有 go to implementation，就是在天然的在隐藏信息，达成：\n这个接口的实现是哪个同事写的？ 我不在意（除非要找个人背锅了） 这个接口的实现具体做了什么，怎么写的，用到了什么技术？ 关我什么事。我只关注它可以达成什么效果，我要给它什么参数，它返回了什么。 接口调用出错了，这可咋办？ 确认调用方式没问题。那抽空修复、替换下实现吧。 就算脱离了接口实现，软件代码也能被理解。这样说明了简化信息很成功，复杂度理所应当的被降低了。\n边界与约定 想要理解领域驱动，理解限界上下文必不可少。直接看限界上下文会感觉很抽象。不过通过信息隐藏，可以很简单的理解、接纳限界上下文的理念。\n约束与限界上下文 边界像是一种约束，只允许边界外知道边界内泄漏出的信息。例如登录失败的原因，只泄漏了 True 或 False，真正的登录失败原因，被我们隐藏起来了。\n这种隐藏方式和我们在面向对象代码语言里的 private 私有特性密切相关。例如边界内的业务对象的 set 方法通常是私有的，不对外公开。这就是一种约束、或者隐藏。边界外只允许获取边界内公开的信息。\n构成边界内/边界外的约束就可以理解为限界上下文。上下文内一个领域、一个聚合，都是一些很纯粹、完整的业务信息，因为他们被约束了，不会泄漏核心信息，不会被外界影响。上下文外则是服务层，应用层，包含诸多的技术细节等“噪音信息”。\n约定先于配置 约定大于配置你可能在某些技术框架里看到过这个理念，可以理解为一种更轻量的约束。这种约定随处可见：\n在 Spring 中，我们依赖注入一个 @Resource 。一般是不会特意配置 name 的 。而是采用默认的约定，即按属性名称注入。 Asp Net Core 会约定文件夹结构，如 Controller、Views\u0026hellip; HomeController.Index() 会被”翻译“为 /Home/Index 路由等。 或者更通用的一种约定，客户端调用后端 REST 规范接口时，一般没有强制性的约束。意味着客户端无法确定接口的输入输出结构。这种情况多靠程序猿们之间的约定，如文档注释，甚至是口头传达。\n这种约定看似需要我们多记住一些规则，增加了心智负担。但反过来想，如果没有这些约定，我们要做的工作是不是会更复杂，要显示配置很多东西，引入更多的技术框架，如 Swagger、Spring XML Configuration\u0026hellip;\n例子说的太多，有点偏上层应用了。回到约定的抽象意义。有时我们只想为特定的服务公开一些领域内的能力，但不可避免地泄漏了这部分能力给所有的服务，此时我们会定下约定：在注释里写上“只允许在 XXXXService 内使用此方法，所有程序员必须遵守此约定“。这条约定就成为了边界的一部分，为功能的抽象边界填砖加瓦。\n总之，这些约定也可以形成边界。\n后言 受限于个人表达水平以及技术尚未炉火纯青。我只能分享这点个人理解了。然后推荐看些 DDD 相关的文章，就算不用，知道 DDD 中的诸多概念后，对写一手容易维护的代码会有很大的帮助。\n","date":"2024-01-18T00:00:00Z","image":"https://blog.zonowry.com/posts/easy_ddd/1_hu_2179606196fd2454.webp","permalink":"https://blog.zonowry.com/posts/easy_ddd/","title":"如何写一手容易维护的代码"},{"content":"前言 尝试用 clash tun 模式来实现过网关，虽然过程很流畅也比较“新潮“，但对于我来说有点魔法了，因为比较难搞清楚 clash 帮我们做了哪些工作，出现问题不好找原因。也可能是我比较“洁癖” ，所以我采用了 iptables + tproxy 这种更加“简单“的方式，clash 只作为流量中继，流量包的路由都依靠 linux 内核的 netfilter 模块实现，这样搭建的网关会更加“可控”一点。\n然后我看了不少 clash + linux netfilter(iptables/nftables) 搭建“富强”网关 的教程文章。步骤都是很简单的，照着做就能实现。但每个人总会有点特殊需求，不去理解这些步骤的奥秘，很难解决一些特殊问题。\n我就是遇到了公网上无法访问我网关上的 docker 服务，debug 排查了好久，虽然最后凭感觉解决了。但一直没有理顺流量是怎么路由的，只是稍有眉目、模棱两可。所以我去尝试理解了过程中每个操作（命令）的底层逻辑，现在写篇文章梳理一下这些知识。\nlinux 网络之 netfilter 首先说说这一切的基石：linux 的 netfilter 模块及延伸工具 iptables。\niptables 只是个命令行工具，依赖 netfilter 内核模块，也即真正实现防火墙功能的是 linux 内核的 netfilter 模块。可惜不仅 iptables 的命令宛若天书，netfilter 的链路也错综复杂，很难去使用。想要理解使用这些工具或命令，必须得先了解一些 netfilter 与 iptables 的基础知识。\niptables 的链 netfilter 提供了 5 个 hook 点，iptables 根据这些 hook 点，搞出了 链 (chain) 的概念，也就内置了 5 个默认链。可以看出 5 个 iptables chian 和 5 个 netfilter hook 一一对应。当然，我们可以添加自定义链，不过想要某个自定义链生效，需要追加一条从内置链跳转到这个自定义链的规则。因为内核的 5 个 hook 点只会触发这 5 个内置链。\nnetfilter hook iptables chain netfilter hook 解释 NF_IP_PRE_ROUTING PREROUTING 接收到的包进入协议栈后立即触发此 hook，在进行任何路由判断 （将包发往哪里）之前 NF_IP_LOCAL_IN INPUT 接收到的包经过路由判断，如果目的是本机，将触发此 hook NF_IP_FORWARD FORWARD 接收到的包经过路由判断，如果目的是其他机器，将触发此 hook NF_IP_LOCAL_OUT OUTPUT 本机产生的准备发送的包，在进入协议栈后立即触发此 hook NF_IP_POST_ROUTING POSTROUTING 本机产生的准备发送的包或者转发的包，在经过路由判断之后， 将触发此 hook iptables 的表与动作 iptables 为了更颗粒度的管理流量，又设计出 table 的概念。用 table 来组织这些链，可以理解为每个 table 根据其用处包含了不同的链。每个 table 都支持一些“动作“。例如 nat 表的 DNAT 动作支持重写目标地址。不过有些动作只在特定的 chain（或者说 hook）上才有意义。例如向 INPUT 链添加 DNAT 动作时，内核会抛出这个错误：ip_tables: DNAT target: used from hooks INPUT, but only usable from PREROUTING/OUTPUT。另一个例子是 mangle 表不允许添加 SNAT 等动作，所以一个动作需要 table + chain 都允许才能被添加。\n表 支持的内置链 支持的动作（部分，仅供参考） mangle 支持全部 5 个内置链 RETURN TPROXY raw PREROUTING OUTPUT TRACE nat PREROUTING INPUT OUTPUT POSTROUTING SNAT DNAT REDIRECT MASQURADE filter INPUT FORWARD OUTPUT 略 security 略 略 每个 table 的 chain 当然也是有触发顺序的，具体顺序可以参考那张著名的 netfilter 流程图 ，或这篇文章的介绍 。\n流量方向 与 iptables 规则 开启内核转发功能 要想把一台 linux 机器配置成有路由转发功能的机器，第一步需要用以下命令开启内核转发功能。\n1 sysctl -w net.ipv4.ip_forward=1 单单这条命令只是将 linux 机器做成中继路由，一般情况下没太大意义。我们还需要处理途径机器的流量。即设定规则将途径流量“路由（转发）”到本机某些程序上（常用如 clash 或者 v2ray ），经代理中转后再原路返回。达成“加速网络”的目的。 iptables 等相关工具就登场了。\n局域网流量跳过处理，直连主路由 linux 系统是可以作为主路由的，但一般的机器没有多个网口，所以都是作为旁路由来辅助主路由。既然作为旁路由来使用，我们只想代理加速公网流量，局域网内机器的流量肯定还是希望通过主路由来直连，没必要再来来回回途径一次旁路由了。所以需要添加一些转发规则，让旁路由跳过局域网内流量，原封不动转出去，让主路由继续去路由。\n结合 netfilter 段落的知识，逆向思考一下要怎么做。首先我们要添加一些路由规则，这些规则最终肯定是注入到 netfilter hook 里的，可以通过 iptables chain 操作 netfikter hook。所以规则要添加到一个合适的 chain 里，iptables 又是通过 table 来组织管理 chain 的。我们还需要找一个合适的 table 来添加 chain（或者说规则）。思考了这些后，我们再回头看命令：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 # clash 链负责处理转发流量 iptables -t mangle -N clash # 让所有流量通过 clash 链进行处理 iptables -t mangle -A PREROUTING -j clash # 目标地址为局域网或保留地址的流量跳过处理 iptables -t mangle -A clash -d 0.0.0.0/8 -j RETURN iptables -t mangle -A clash -d 127.0.0.0/8 -j RETURN iptables -t mangle -A clash -d 10.0.0.0/8 -j RETURN iptables -t mangle -A clash -d 172.16.0.0/12 -j RETURN iptables -t mangle -A clash -d 192.168.0.0/16 -j RETURN iptables -t mangle -A clash -d 169.254.0.0/16 -j RETURN iptables -t mangle -A clash -d 224.0.0.0/4 -j RETURN iptables -t mangle -A clash -d 240.0.0.0/4 -j RETURN 首先我们新建了一个自定义链管理规则：iptables -t mangle -N clash 然后从内置链 PREROUTING 跳转而来：iptables -t mangle -A PREROUTING -j clash 当然我们可以直接不写这两句，直接将规则添加到 PREROUTING 链。但那样写不是很规范，不推荐直接向内置链（这里是 PREROUTING ）添加规则。 然后追加局域网 IP 直连规则到 clash 表中 我们使用的表是 mangle 表，链是 链。 总而言之，最终实现了局域网机器流量发到旁路由时，旁路由发现目标地址是局域网内 ip，跳过处理，转发出去给到主路由，就是主路由和源主机直接通信了，之后的网络传输本网关就不会参与了。 中转外网流量，clash 透明代理 由于上一步我们跳过了内部（局域网内）流量，剩下的流量基本就是外部（互联网）流量了。这些外部流量应该要转发到 clash 中进行透明代理。\n虽然可以简单的通过 REDIRECT 动作将流量转发到 7893 端口。但 REDIRECT 不能很好的支持 UDP 流量。所以采用 TPROXY 方式，这样 TCP 和 UDP 都能支持。\n1 2 3 4 5 6 7 8 9 10 11 # tproxy 7893（clash） 端口，并打上 mark 666 命中策略，走 666 路由表 iptables -t mangle -A clash -p tcp -j TPROXY --on-port 7893 --tproxy-mark 666 iptables -t mangle -A clash -p udp -j TPROXY --on-port 7893 --tproxy-mark 666 # 转发所有 DNS 查询到 1053 端口 # 此操作会导致所有 DNS 请求全部返回虚假 IP(fake ip 198.18.0.1/16) iptables -t nat -I PREROUTING -p udp --dport 53 -j REDIRECT --to 1053 # 添加策略与路由表（） ip rule add fwmark 666 lookup 666 ip route add local 0.0.0.0/0 dev lo table 666 前两句 iptables 命令，追加了两条 TPROXY 规则。将 tcp \u0026amp; udp 流量转发到 clash 的 7893 端口，且打了 666 标记。\n因为 TPROXY 不会修改 IP 数据包，数据包的 dest ip 一般都是外网地址，所以数据包下一跳会直接 forward 转出到下一跳机器上。因此 TPROXY 大部分情况都需要搭配 ip route 策略路由一起使用。比如我们这里就是新建了一个名为 666 的路由表，此路由表会将所有数据包发到本地回环上。这样就阻断了 forward 过程，相当于让（ tproxy 过的）数据包重新走一边网络栈流程。这样数据包就可以转发到 7893 端口上了，然后我们只让有 666 标记的数据包经过此路由表。\n代理网关本机的流量 经过以上步骤，局域网内的其它机器已可以正常使用本网关了。当然，一台 llinux 机器只用来当一个网关太浪费了，还可以跑各种服务以及日常使用。顺便将本机的流量也代理一下，也即代理本机发出（经过 OUTPUT 链）的数据包。\n首先与上一步类似的步骤，将本机发出的流量（OUTPUT）打上标记，触发重新路由。这样本机发出的流量就和局域网内其它机器进入的流量相同了，路由的流程也就一样了。不过 OUTPUT 上的数据包也会包含 clash 发出流量，这样会出现数据包死循环，得处理一下。只需要跳过 clash 程序发出的数据包，避免死循环。用 clash 用户启动 clash 程序，根据 uid 跳过数据包即可。。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 # clash_local 链负责处理网关本身发出的流量 iptables -t mangle -N clash_local # nerdctl 容器流量重新路由 #iptables -t mangle -A clash_local -i nerdctl2 -p udp -j MARK --set-mark 666 #iptables -t mangle -A clash_local -i nerdctl2 -p tcp -j MARK --set-mark 666 # 跳过内网流量 iptables -t mangle -A clash_local -d 0.0.0.0/8 -j RETURN iptables -t mangle -A clash_local -d 127.0.0.0/8 -j RETURN iptables -t mangle -A clash_local -d 10.0.0.0/8 -j RETURN iptables -t mangle -A clash_local -d 172.16.0.0/12 -j RETURN iptables -t mangle -A clash_local -d 192.168.0.0/16 -j RETURN iptables -t mangle -A clash_local -d 169.254.0.0/16 -j RETURN iptables -t mangle -A clash_local -d 224.0.0.0/4 -j RETURN iptables -t mangle -A clash_local -d 240.0.0.0/4 -j RETURN # 为本机发出的流量打 mark iptables -t mangle -A clash_local -p tcp -j MARK --set-mark 666 iptables -t mangle -A clash_local -p udp -j MARdocK --set-mark 666 # 跳过 clash 程序本身发出的流量, 防止死循环(clash 程序需要使用 \u0026#34;clash\u0026#34; 用户启动) iptables -t mangle -A OUTPUT -p tcp -m owner --uid-owner clash -j RETURN iptables -t mangle -A OUTPUT -p udp -m owner --uid-owner clash -j RETURN # 让本机发出的流量跳转到 clash_local # clash_local 链会为本机流量打 mark, 打过 mark 的流量会重新回到 PREROUTING 上 iptables -t mangle -A OUTPUT -j clash_local 外网访问内网 docker 问题 也可以说外网访问局域网内机器（非网关机器）的问题。我们这样配置好后，会发现无法从外网访问内网的 docker 服务（设置路由器端口转发）。可以通过手机流量访问测试。\n我是参考该 github issue 受到了启发，最终解决了。\n1 2 # 跳过 docker0 的 ip 范围。即跳过 docker 服务的出站数据包 sudo iptables -t mangle -A clash -p tcp -s 172.18.0.0/16 -j RETURN 然后以下是个人的推测，可能有误，仅供参考。\n首先手机入站数据包经过路由器，NAT 到 docker 服务（网关机器）上。此时因为 dest ip 是内网 ip，clash 链 会跳过。DOCKER 链 接手处理，通过 DNAT 转发到了 docker0 bridge 网卡上，这几步都很正常。顺利到达 docker 容器。\n随后是 docker 容器的出站数据包，此时数据包会从 docker0 bridge 发到宿主机的物理网卡 eth 网卡。这时数据包之于宿主机来说，是一个入站数据包。数据包会经过 PREROUTING 链，jump 到 clash 链，而此时的 dest ip 为手机的 ip 。会被转发到 clash 上处理，但这个数据包只在出站时转发给 clash 处理。入站的时候跳过了。估计 clash 无法处理这个数据包，可能就丢弃了。就出现了外网无法访问内网 docker 容器的问题。\n所以根据 source ip 判断， 将 docker 容器的数据包也跳过。跳过后就解决了～\n参考 第一篇万字长文：围绕透明代理的又一次探究 「译」深入理解 iptables 和 netfilter 架构 树莓派 Clash 透明代理(TProxy)_ tpclash wiki - 2、进阶流量控制 。 iptables 的四表五链与 NAT 工作原理 _ https://www.zhaohuabing.com/learning-linux/docs/tproxy/ ","date":"2023-03-01T00:00:00Z","image":"https://arthurchiao.art/assets/img/deep-dive-into-iptables-netfilter/Netfilter-packet-flow.svg","permalink":"https://blog.zonowry.com/posts/clash_iptables_tproxy/","title":"iptables + clash 透明网关实践与总结"}]