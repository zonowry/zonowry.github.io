---
tag:
- article
- blog
- concurrent
creation date: 2024-01-26 15:59
name: "how to do safe concurrent programming"
title: "怎样安全的并发编程"
lastmod date: 2024-02-26 22:56
description: "我们仍未确定那天所见变量的状态"

description: 我们仍未确定那天所见变量的状态
date: 2024-02-29
lastmod: 2024-02-29 23:36
toc: true
isCJKLanguage: true
keywords:
  - zonowry
  - 怎样安全的并发编程
  - concurrent
  - threads
  - 并发
  - 反应式
  - 协程
  - coroutine
  - reactive
---

## 引言

说到并发，首先会想到多线程。若只关注多线程如何使用，却对并发编程没有深入的了解，很容易在代码里挖坑，变成这个段子的模样：“从前有个程序员遇到了一个性能问题。他想，没事，我懂，用线程就好了。现他有在个两题了问“。

为了避免这种情况，我们该思考“为什么需要多线程，为什么 `js` 里没有多线程？”等诸类问题。将多线程看成是并发的一种手段，也就是让我们往下面 （the lower）走一点，越过线程理解并发编程。

> 如果逻辑控制流在时间上重叠，那么它们就是**并发的**（concurrent）—— 《CSAPP》

## 理论指导实践

分析 `thread（线程）`、`coroutine（协程）`、`reactive（反应式）`、`event/task queue（任务队列）`等各种并发**手段**。不讨论它们的用法、优劣，而是关注它们的的相似之处——它们实际都是通过编排、调度**逻辑控制流**实现的并发。所以只需要搞清楚它们是如何调度**执行单元**的，就掌握了核心~~科技~~。

> 逻辑控制流，底层一点的理解是硬件电路形成的一组逻辑。应用级一点的解释是一个可以被执行的内容，可能是线程、协程、一个可观察对象 Observable、Subscription、FutureTask、Event Callback......等等。不过用 `CSAPP` 书中的**逻辑控制流**表示一个可执行内容有点极简，所以下文就称之为**任务**或**执行单元**吧，**代表一个可被执行的片段**（you know it）。

### 抢占式调度

首先是最常见的抢占式调度，执行单元间呈**竞争**关系，A 任务与 B 任务互相争夺执行机会。最常见的例子是“操作系统内核利用 CPU 时钟中断，达成多线程并发“。每次中断都代表某个线程抢到了 CPU 时间片”。因为 CPU 中断是纳秒级的，实际效果是内核在飞快的切换执行单元以交错执行。提供一种所有执行单元在**并行**的假象。在多核心 CPU 下，内核的抢占式调度也足以实现真正的**并行**。

抢占式调度下，执行单元无法确定自己什么时候会被执行，且任何时刻都可能会被中断执行。反过来说，只要我们基于此特性，处理好执行单元的竞争与中断，就可以实现一个抢占式调度器。也可以看出抢占式调度的好处是不会存在独占情况——某个执行单元永远占用着 CPU。因为每个执行单元都有被执行的机会，就像在等红绿灯一样。

### 协作式调度

协作式调度可以引出一大堆技术，例如 `IO 多路复用` 、`迭代器`、`事件驱动` 等等。

它们都有一个点——主动让渡控制权，或者说主动挂起的（释放并等待）。A 任务与 B 任务可以在**合适**的时机**主动**让渡出控制权。特点是持有控制权的任务主动中断，~~抛开现实不谈（例如 CPU 中断），~~这也突出了协作式调度的优点与理念——“调度不会影响**顺序性**“。因为我们是主动让出的，继续执行时可以找到让渡时的节点来保证顺序性，也可以理解为调度器会帮我们将执行单元恢复到让渡前一刻的状态，然后就像没让渡过一样继续执行。

协作式调度，执行单元知道自己什么时候会让出，但同时对程序员也是**无感知**的，因为当再次拿到控制权时，协作式调度器可以保持顺序性[^注：顺序性]。这个特性提高了程序员们的并发编程体验。于是出现了很多协作式调度框架。抽象的角度看，不论是 `Reactive Stream`，还是 `coroutine` ，在我看来都是协作式调度的不同实现。它们都有着执行单元可以主动挂起的特性，与其它执行单元**协作式**的完成逻辑。

## 实践中的问题

是时候为线程正名一下了，虽然前面段落回避提及线程，但现在开始线程必不可少，因为线程作为系统内核最小的调度单位，实现**并行**基本[^注：单线程并行]离不开线程。协程、反应式等用户态的并发模型到底还是跑在线程上的。

单线程的话，就不存在着并发编程中的问题，无非就是线程安全了。原因只有**并发环境下访问共享可变的状态**一种。但为什么**共享状态**这个操作会引起问题？因为数据读写不一致。为什么会读写不一致？需要搞清楚并发下计算机是如何读写状态的。

> 专业一点的说共享状态就是**竞态条件**。也说明两个执行单元可能有某种依赖关系，它们需要协商好谁可以使用这个状态。

### 缓存一致性

假设计算机的内存**非常快**且**非常大**，那我们就不需要担心**缓存一致性**问题了，为什么？因为每次读取状态，都是最新的状态，这是纳秒级实时读写。~~（最后说一次，时间要加速了）~~，这是美好的未来。可现实世界的计算机是有极限的（~~我不做电子计算机了！JOJO！~~），计算机的妥协设计是每个 CPU 核心都有一块**独立的**非常快，但非常小的内存，称之为**高速缓存**；再加一块速度尚可（远不及 CPU 计算速度），但非常大的内存，它就是我们的内存条，称之为**主内存**。

两块内存特性互补，让数据读写不至于拖慢 CPU 计算。妥协的代价就是数据一致性问题，或者说数据可见性问题。因为 cpu 运行一个线程时，需要先从主内存读取数据拷贝到高速缓存里，之后就是 cpu 与高速缓存的时间了，期间 CPU 会适时的将高速缓存里的堆积数据刷写到主内存中。问题出在线程间可以共享数据，会牵扯到**数据同步**（~~最小的分布式了吧？~~），有数据同步就不可避免的有一致性问题了，与分布式、数据库领域的**数据一致性**大同小异。

高级语言为了避免我们太操心这些事情，抽象了运行时内存区域（堆栈、常量区、方法区...），然后设计了内存模型，负责线程间通信，保证线程间数据同步，线程空间隔离。让多线程容易使用，程序员们要操心的事情变少了（不用和系统底层打交道），但也也让线程间通信变的陷阱重重。

### 读写有序性

不考虑性能，假设不存在中间**缓存**，每个 CPU 核心实时读写主内存，可以保证所有线程共享数据的**一致性**，就像 `java` 中 `volatile`、数据库的 `读已提交` 事务级别。但这样能解决线程安全问题吗？还是不行，因为计算机并不会 `line by line` 的执行代码，因为计算机/虚拟机会在不影响语义的情况下，优化代码的执行顺序。也就是优化后应该与不优化执行的结果一致，称之为**重排序**。

**多个线程**只共享**一个变量**时，`volatile` 或者我们的假设确实有用，指令重排序对我们来说不会是问题。但**多个线程**共享**多个变量**时，指令重排序的情况就很复杂了。线程是独立的，无法确保另一个线程的重排序会不会影响。举个简单的例子，方便理解：

```kotlin
var value: Int = 0;
var flag: Boolean = false;
​
fun init() {
	value = 8;
	flag = true;
}
​
fun getValue() {
	if (flag) {
		println(value);
	}
}


fun main() {
	// thread 1 可能会先执行 flag = true，后执行 value = 8
	thread { init(); }
	// 在这钟情况下，thread 2 则有可能 print 0;
	thread { getValue() }
}
```

如果没有重排序，因为我们知道线程就算是抢占的，交错执行。但也不会造成 `print`
0 的情况，因为赋值 `value = 8` 是**原子操作**（下面介绍）。~~2 个线程，2 个共享变量，非常简单代码，使我的大脑宕机，爱来自.....~~

真实的代码会更复杂，可见编译器和 CPU 很难确保**重排序**优化在**多线程多共享**的情况下不会出现异外结果。就像这个理论不该出现的 `print` 0，即使我们理解线程的交错执行，且阅读并人脑编译了代码可能的执行过程，但因为指令重排序的存在，这一切变得混沌。

### 原子一致性

进一步假设~~（现在是幻想时间）~~，不存在指令重排序，不存在缓存一致性问题，相当于 `java` 的 `volatile` 关键字的效果。线程安全问题还会存在吗？还是会存在，因为程序不仅有指令、数据，还有**算法**（**逻辑**）。

编排一系列指令形成逻辑，可以称之为**算法**或操作（~~算法帅一点，所以下文统称算法~~）。既然是一系列指令，那么每条指令都有可能会被系统内核中断或被其它并行的线程影响，导致算法结果不符合预期。而原子性的百科定义是：

> 原文：**线性一致性**（Linearizability），或称**原子一致性**或**严格一致性**指的是程序在执行的历史中在存在可线性化点 P 的执行模型，这意味着一个操作将在程序的调用和返回之间的某个点 P 起作用。这里“起作用”的意思是被系统中并发运行的所有其他线程所感知。

大概意思是如果某个指令被执行，其它线程一定会知道这个指令被某个线程执行了，就像单线程一样，等待执行的代码行可以感知到已执行的代码行。或者常见的理解基于「原子是不可再分割的最小物质」并发原子性就是「不可再打断的最小操作序列」。这个解释与**数据库的原子性**「要么全都成功，要么全都失败」异曲同工，当然细说还是有区别的，例如并发的原子性不会 `rollback` 。

我的解释是，如果一个算法执行过程中，即使被内核中断切换了线程，或存在共享状态的并行线程，也不会被影响结果。那就可以称之为具有**原子性**，因为说明了这是一个**不会被打断**的算法操作。

原子性我认为是比较容易理解的，因为非原子性算法造成的影响用户态可以很明显的感知到。例如两个线程同时执行 `i++` ，最后 `i` 的结果通常会小于预期值。但是如何运用原子性、使线程串行是另一个话题了。

## 高速的安全并发

步入正题，前文可得，只要我们灵活运用三大特性即可避免线程安全问题。不过我们并发初衷可不是为了安全，而是 fot the speed！速度！

`java` 作者在他的书中写过，如何修复线程安全问题：

> 如果当多个线程访问同一个可变的状态变量时没有使用合适的同步，那么程序就会出现错误。有三种方式可以修复该问题：
>
> - 不在线程之间共享该状态变量
> - 将该状态变量修改为不可变的变量
> - 再访问该状态变量时使用同步

### 串行化线程

先看最简单的一种：**在访问该状态变量时使用同步**。

### DRAFT....

首先是原子性，只要保证原子性，我们的算法肯定是线程安全的。**加锁**可以避免算法被外界影响，所以加锁可以实现原子性。

线程锁的种类就多了，最常见的就是悲观锁，或者说互斥同步锁。

> DRAFT...

### 函数式理念

**将该状态变量修改为不可变的变量**，不可变变量。函数式思想，一种优雅至极的方案，但会让你束手束脚，不过如果完美贯彻函数式，应该会很流畅，不过需要很高的脑力吧...

> DRAFT...

### 最终一致性

再来看好像最简单的一种：**不在线程之间共享该状态变量**。作者本意应该不是让我们放弃，而是让我们自己想办法，不共享状态，但我们又需要访问该状态。只要我们可以接受短暂的线程不安全，退一步，就会有很多方案。

> DRAFT...

## 参考

- [并发之痛 Thread，Goroutine，Actor](https://jolestar.com/parallel-programming-model-thread-goroutine-actor/)
- [既然 CPU 有缓存一致性协议（MESI），为什么 JMM 还需要 volatile 关键字？](https://www.zhihu.com/question/296949412)

[^注：顺序性]: 可能会对 `rx` 的顺序性提出质疑，这里非指过程式一样的代码的编写顺序，例如容易理解的协程的顺序性，而是“可以较为容易”的预测代码执行的顺序。例如 `rx` 的 `obserable.flatmap().reduce().publishOn().map().tap()` 例子，还是可以预测出这段代码的整体顺序性的，只是操作符联合起来会很复杂，让人难以理解，不过还是可以说 `rx` 是有一定顺序性的，毕竟本质上是一个流处理，流的流转过程就是顺序。
[^注：单线程并行]: 如果不把异步 IO 看作一个特殊的“线程”，那将 IO 读写操作交由内核调度，注册回调后继续干活，变相实现了一个线程逻辑计算的同时，其它 IO 硬件也正在读写数据（如网卡），实现并行处理：一个 IO 硬件，一个 CPU。虽然多数场景我们都是要挂起线程，等待 IO 硬件响应的。再展开就是 IO 模型的话题了，本文不过多讨论，不过也可以看出 IO 模型与并发编程的关系密不可分。
